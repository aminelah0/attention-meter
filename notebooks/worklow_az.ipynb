{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from attention.img_proc.img_process import *\n",
    "from attention.img_proc.img_split import *\n",
    "from attention.models.face_models import *\n",
    "from attention.utils.img_plot import *\n",
    "from attention.utils.utilities import *\n",
    "from attention.params import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get attention_data directory\n",
    "current_directory = os.getcwd()\n",
    "data_directory = os.path.join(current_directory, os.pardir, \"attention_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_folder_path = os.path.join(data_directory, \"video\")\n",
    "# video_name = \"video2.MOV\"\n",
    "# video_path = os.path.join(video_folder_path, video_name)\n",
    "# frames = extract_video_frames(video_path, \n",
    "#                               period_sec=1,\n",
    "#                               start_sec=35, end_sec=185)\n",
    "\n",
    "# # Saving the frames\n",
    "# image_folder_path = os.path.join(data_directory, \"frames\")\n",
    "# for timestamp, frame in frames.items():\n",
    "#     frame_name = video_name.split('.')[0] + f'_ds{int(timestamp * 10):05}'\n",
    "#     save_image(frame, frame_name + '.png', image_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: from photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = os.path.join(data_directory, \"frames\")\n",
    "for idx, filename in enumerate(sorted(os.listdir(image_folder_path))):\n",
    "    os.rename(os.path.join(image_folder_path, filename), os.path.join(image_folder_path, f'frame_ds{idx * 10:05}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the face recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the face recognition model\n",
    "known_folder_path = os.path.join(data_directory, os.pardir, \"attention_known_faces\")\n",
    "known_paths = load_image_paths(known_folder_path)\n",
    "known_names = list(known_paths.keys())\n",
    "known_faces = [read_image(image_path) for image_path in known_paths.values()]\n",
    "known_encodings = train_faces(known_faces, known_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS:\n",
    "n_split_w = 6\n",
    "n_split_h = 6\n",
    "landmark_idx = LEFT_EYE_EDGES  + LEFT_IRIS_CENTER + RIGHT_EYE_EDGES + RIGHT_IRIS_CENTER\n",
    "\n",
    "# Dataframe columns\n",
    "df_columns =  ['frame',\n",
    "'timestamp',\n",
    "'face_idx',\n",
    "'recognition_prediction',\n",
    "'recognition_distance',\n",
    "'attentive',\n",
    "'left_prediction',\n",
    "'left_score',\n",
    "'right_prediction',\n",
    "'right_score',\n",
    "'head_direction_prediction',\n",
    "'head_direction_score',\n",
    "'head_inclination_prediction',\n",
    "'head_inclination_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = os.path.join(data_directory, \"frames\")\n",
    "image_paths = load_image_paths(image_folder_path)\n",
    "\n",
    "attention_df = pd.DataFrame(columns=df_columns) \n",
    "\n",
    "for image_name, image_path in image_paths.items():\n",
    "    \n",
    "    # Loading image\n",
    "    image = read_image(image_path)\n",
    "    timestamp = int(image_name.split('_ds')[1]) if '_ds' in image_name else np.nan\n",
    "    image_summary, ratio_summary = resize_image(image, 1920)\n",
    "    # Splitting image\n",
    "    crops = split_image(image, n_split_w, n_split_h, 0.05, 0.05)\n",
    "    # Generating bboxes for each crop\n",
    "    bbox_crop_list = []\n",
    "    bbox_crop_list_absolute = []\n",
    "    for crop in crops:\n",
    "        coord_set = detect_face(crop.image)\n",
    "        bbox_crop_list.append(coord_set)\n",
    "        coord_set_absolute = reconstruct_coord(crop, coord_set)\n",
    "        bbox_crop_list_absolute.append(coord_set_absolute)\n",
    "    bbox_crop_list_absolute\n",
    "    # Eliminating duplicates bboxes\n",
    "    bbox_list = bbox_merge(bbox_crop_list_absolute, intersect_threshold=0.6)\n",
    "    # # Drawing the unique bboxes on the original image\n",
    "    # image_output = annotate_bboxes(image, bbox_list)\n",
    "    # # Saving the image with its bboxes\n",
    "    # bbox_path = os.path.join(data_directory, \"output_bbox\")\n",
    "    # save_image(image_output, image_name + '.png', bbox_path)\n",
    "    \n",
    "    # Generating face crops\n",
    "    faces = crop_faces(image, bbox_list)\n",
    "    # # Saving face crops\n",
    "    # face_path = os.path.join(data_directory, \"face_crops\")\n",
    "    # for face_idx, face in enumerate(faces):\n",
    "    #     face_name = image_name + f'_{face_idx}'\n",
    "    #     save_image(face, face_name + '.png', face_path)\n",
    "    \n",
    "    # Generating eye and iris landmarks\n",
    "    for face_idx, face in enumerate(faces):\n",
    "        \n",
    "        face_name = image_name + f'_{face_idx}'\n",
    "        mp_landmarks = find_landmarks(face)\n",
    "        if mp_landmarks:                # Only run attention/ recognition if it detects a face\n",
    "            # Converting the Mediapipe landmark to a standard system of coordinates\n",
    "            landmark_list = convert_landmarks(face, mp_landmarks)\n",
    "            # # Drawing the face mesh on the face\n",
    "            # face_mesh = annotate_mesh(face, mp_landmarks)\n",
    "            # # Saving face with complete mesh\n",
    "            # mesh_path = os.path.join(data_directory, \"output_mesh\")\n",
    "            # save_image(face_mesh, face_name + '.png', mesh_path)\n",
    "            \n",
    "            # Detecting eye direction and attention\n",
    "            face_name = image_name + f'_{face_idx}'\n",
    "            eye_directions = detect_eye_directions(landmark_list, extreme_threshold = 0.63, detailed_threshold_main = 0.6, detailed_threshold_comp = 0.45)\n",
    "            eye_inclinations = detect_eye_inclinations(landmark_list, threshold = 0.23)\n",
    "            head_direction = detect_head_direction(landmark_list, left_threshold = 0.35, right_threshold = 1)\n",
    "            head_inclination = detect_head_inclination(landmark_list, down_threshold = 2.3)\n",
    "            attention, attention_driver = is_attentive(eye_directions, eye_inclinations, head_direction, head_inclination)\n",
    "            # Drawing iris landmarks + annotating attention results on original image\n",
    "            prediction_lefteye_direction, score_lefteye_direction = eye_directions['left']\n",
    "            prediction_righteye_direction, score_righteye_direction = eye_directions['right']\n",
    "            prediction_lefteye_inclination, score_lefteye_inclination = eye_inclinations['left']\n",
    "            prediction_righteye_inclination, score_righteye_inclination = eye_inclinations['right']\n",
    "            prediction_head_direction, score_head_direction = head_direction\n",
    "            prediction_head_inclination, score_head_inclination = head_inclination\n",
    "            prediction_attention = 'attentive' if attention else 'inattentive'\n",
    "            # face_attention = annotate_attention(face, landmark_list, \n",
    "            #                                         prediction_lefteye_direction, score_lefteye_direction, \n",
    "            #                                         prediction_righteye_direction, score_righteye_direction,\n",
    "            #                                         prediction_lefteye_inclination, score_lefteye_inclination, \n",
    "            #                                         prediction_righteye_inclination, score_righteye_inclination,\n",
    "            #                                         prediction_head_direction, score_head_direction,\n",
    "            #                                         prediction_head_inclination, score_head_inclination,\n",
    "            #                                         prediction_attention)\n",
    "            # # Saving attention image output\n",
    "            # attention_path = os.path.join(data_directory, \"output_attention\")\n",
    "            # save_image(face_attention, face_name + '.png', attention_path)\n",
    "        \n",
    "        \n",
    "            # Recognizing a face\n",
    "            face_name = image_name + f'_{face_idx}'\n",
    "            face_prediction = recognize_face(face, known_encodings)\n",
    "            # Annotating name and distance on the face image\n",
    "            prediction_recognition, distance_recognition = face_prediction\n",
    "            # face_recognition = annotate_recognition(face, prediction_recognition, distance_recognition)\n",
    "            # # Saving recognition image output\n",
    "            # recognition_path = os.path.join(data_directory, \"output_recognition\")\n",
    "            # save_image(face_recognition, face_name + '.png', recognition_path)\n",
    "            \n",
    "            \n",
    "            # Generating summary image\n",
    "            # Annotating with key info (bbox, attentiveness, recognition)\n",
    "            recognition = False if pd.isna(prediction_recognition) else True\n",
    "            bbox_face = bbox_list[face_idx]\n",
    "            image_summary = annotate_summary(image_summary, ratio_summary, \n",
    "                                             bbox_face, \n",
    "                                             attention, attention_driver, \n",
    "                                             recognition)\n",
    "            \n",
    "            \n",
    "            # Saving data in the dataframe\n",
    "            attention_df.loc[len(attention_df)] = [image_name,\n",
    "                                                    timestamp,\n",
    "                                                    face_idx,\n",
    "                                                    prediction_recognition, distance_recognition,\n",
    "                                                    attention,\n",
    "                                                    prediction_lefteye_direction, score_lefteye_direction,\n",
    "                                                    prediction_righteye_direction, score_righteye_direction,\n",
    "                                                    prediction_head_direction, score_head_direction,\n",
    "                                                    prediction_head_inclination, score_head_inclination]\n",
    "                \n",
    "        \n",
    "        # Saving summary image once all faces done\n",
    "        summary_path = os.path.join(data_directory, \"output_summary\")\n",
    "        save_image(image_summary, image_name + '.png', summary_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the timestamps\n",
    "attention_df = attention_df.sort_values(by=['timestamp', 'face_idx']).reset_index(drop=True)\n",
    "grouping_factor = 10\n",
    "timestamps = attention_df[\"timestamp\"].unique()\n",
    "timestamp_dict = {timestamps[i]: timestamps[i - i % grouping_factor] for i in range(len(timestamps))}\n",
    "time_group = attention_df['timestamp'].map(timestamp_dict)\n",
    "attention_df.insert(2, 'time_group', time_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_df.to_csv(os.path.join(data_directory,'attention_output.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
