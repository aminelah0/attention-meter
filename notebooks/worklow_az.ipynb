{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from attention.img_proc.img_process import *\n",
    "from attention.img_proc.img_split import *\n",
    "from attention.models.face_models import *\n",
    "from attention.utils.img_plot import *\n",
    "from attention.utils.utilities import *\n",
    "from attention.params import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get attention_data directory\n",
    "current_directory = os.getcwd()\n",
    "data_directory = os.path.join(current_directory, os.pardir, \"attention_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting video to frames:\n",
    "video_folder_path = os.path.join(data_directory, \"video\")\n",
    "video_name = \"Midbatch.MOV\"\n",
    "video_path = os.path.join(video_folder_path, video_name)\n",
    "frames = extract_video_frames(video_path, \n",
    "                              period_sec=1,\n",
    "                              start_sec=60, end_sec=75)\n",
    "\n",
    "# Saving the frames\n",
    "image_folder_path = os.path.join(data_directory, \"frames\")\n",
    "for idx, frame in enumerate(frames):\n",
    "    save_image(frame, video_name.split('.')[0] + f'_f{idx}.png', image_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the face recognition model\n",
    "known_folder_path = os.path.join(data_directory, \"known_faces\")\n",
    "known_paths = load_image_paths(known_folder_path)\n",
    "known_names = list(known_paths.keys())\n",
    "known_faces = [read_image(image_path) for image_path in known_paths.values()]\n",
    "known_encodings = train_faces(known_faces, known_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS:\n",
    "n_split_w = 6\n",
    "n_split_h = 6\n",
    "landmark_idx = LEFT_EYE_EDGES  + LEFT_IRIS_CENTER + RIGHT_EYE_EDGES + RIGHT_IRIS_CENTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = os.path.join(data_directory, \"frames\")\n",
    "image_paths = load_image_paths(image_folder_path)\n",
    "\n",
    "for image_name, image_path in image_paths.items():\n",
    "    # Loading image\n",
    "    image = read_image(image_path)\n",
    "    # Splitting image\n",
    "    crops = split_image(image, n_split_w, n_split_h, 0.05, 0.05)\n",
    "    # Generating bboxes for each crop\n",
    "    bbox_crop_list = []\n",
    "    bbox_crop_list_absolute = []\n",
    "    for crop in crops:\n",
    "        coord_set = detect_face(crop.image)\n",
    "        bbox_crop_list.append(coord_set)\n",
    "        coord_set_absolute = reconstruct_coord(crop, coord_set)\n",
    "        bbox_crop_list_absolute.append(coord_set_absolute)\n",
    "    bbox_crop_list_absolute\n",
    "    # Eliminating duplicates bboxes\n",
    "    bbox_list = bbox_merge(bbox_crop_list_absolute, intersect_threshold=0.6)\n",
    "    # Drawing the unique bboxes on the original image\n",
    "    image_output = annotate_bboxes(image, bbox_list)\n",
    "    # Saving the image with its bboxes\n",
    "    bbox_path = os.path.join(data_directory, \"output_bbox\")\n",
    "    save_image(image_output, image_name + '.png', bbox_path)\n",
    "    \n",
    "    #Â Generating face crops\n",
    "    faces = crop_faces(image, bbox_list)\n",
    "    # Saving face crops\n",
    "    face_path = os.path.join(data_directory, \"face_crops\")\n",
    "    for idx, face in enumerate(faces):\n",
    "        face_name = image_name + f'_{idx}'\n",
    "        save_image(face, face_name + '.png', face_path)\n",
    "    \n",
    "    # Generating eye and iris landmarks\n",
    "    for idx, face in enumerate(faces):\n",
    "        face_name = image_name + f'_{idx}'\n",
    "        mp_landmarks = find_landmarks(face)\n",
    "        if mp_landmarks:                # Only run attention/ recognition if it detects a face\n",
    "            # Converting the Mediapipe landmark to a standard system of coordinates\n",
    "            landmark_list = convert_landmarks(face, mp_landmarks)\n",
    "            # Drawing the face mesh on the face\n",
    "            face_mesh = annotate_mesh(face, mp_landmarks)\n",
    "            # Saving face with complete mesh\n",
    "            mesh_path = os.path.join(data_directory, \"output_mesh\")\n",
    "            save_image(face_mesh, face_name + '.png', mesh_path)\n",
    "            \n",
    "            # Detecting eye direction and attention\n",
    "            face_name = image_name + f'_{idx}'\n",
    "            eye_directions = detect_eye_directions(landmark_list, threshold = 0.63)\n",
    "            attention = is_attentive(eye_directions)\n",
    "            # Drawing iris landmarks + annotating attention results on original image\n",
    "            prediction_left, score_left = eye_directions['left']\n",
    "            prediction_right, score_right = eye_directions['right']\n",
    "            prediction_attention = 'attentive' if attention else 'inattentive'\n",
    "            face_attention = annotate_iris_attention(face, landmark_list, \n",
    "                                                    prediction_left, score_left, \n",
    "                                                    prediction_right, score_right,\n",
    "                                                    prediction_attention)\n",
    "            # Saving attention image output\n",
    "            attention_path = os.path.join(data_directory, \"output_attention\")\n",
    "            save_image(face_attention, face_name + '.png', attention_path)\n",
    "        \n",
    "            # Recognizing a face\n",
    "            face_name = image_name + f'_{idx}'\n",
    "            face_prediction = recognize_face(face, known_encodings)\n",
    "            #Annotating name and distance on the face image\n",
    "            prediction_name, distance = face_prediction\n",
    "            face_recognition = annotate_recognition(face, prediction_name, distance)\n",
    "            # Saving recognition image output\n",
    "            recognition_path = os.path.join(data_directory, \"output_recognition\")\n",
    "            save_image(face_recognition, face_name + '.png', recognition_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
