{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import cv2\n",
    "from mediapipe.python.solutions import face_detection, face_mesh, drawing_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import mediapipe.framework.formats.landmark_pb2 as mp_landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/lancelotbosseler/code/labosseler/final-project/final-attention/notebooks/trial-images/dark-4m-cropped.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face detection return a plot \n",
    "def face_detector(image_path: str) -> list:                           # output = list of ndarrays  \n",
    "    with face_detection.FaceDetection(\n",
    "        model_selection=1, min_detection_confidence=0.5) as face_det:\n",
    "        faces = []\n",
    "        les_scores = []\n",
    "        image_array = cv2.imread(image_path)  \n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "        image_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "        results = face_det.process(image_rgb)\n",
    "        fig, axs = plt.subplots(1, len(results.detections), figsize=(20, 10))\n",
    "        if results.detections: \n",
    "            for i, detection in enumerate(results.detections): \n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                h, w, _ = image_rgb.shape\n",
    "                x1 = int(bbox.xmin * w) - int(0.05 * int(bbox.xmin * w))\n",
    "                y1 = int(bbox.ymin * h) - int(0.05 * int(bbox.ymin * h))\n",
    "                x2 = int((bbox.xmin + bbox.width) * w) + int(0.05 * int(bbox.xmin * w))\n",
    "                y2 = int((bbox.ymin + bbox.height) * h) + int(0.05 * int(bbox.ymin * h))\n",
    "                cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                face = image_rgb[y1:y2, x1:x2]\n",
    "                face = cv2.resize(face, (400, 400))\n",
    "                faces.append(face)\n",
    "                les_scores.append(detection.score)\n",
    "                axs[i].imshow(annotated_image)\n",
    "                axs[i].set_title(f\"Face {i+1}\")\n",
    "    return faces  #, les_scores         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d5199d47e09c264d56960d495f87fb2e9db5e02fdeb85c0cdb762db9136ad67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
