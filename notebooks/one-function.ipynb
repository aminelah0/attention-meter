{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import cv2\n",
    "from mediapipe.python.solutions import face_detection, face_mesh, drawing_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import mediapipe.framework.formats.landmark_pb2 as mp_landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/lancelotbosseler/code/labosseler/final-project/final-attention/notebooks/trial-images/no-face.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face detection \n",
    "def face_detector(image_path: str) -> list:                           # output = list of ndarrays  \n",
    "    with face_detection.FaceDetection(\n",
    "        model_selection=1, min_detection_confidence=0.5) as face_det:\n",
    "        faces = []\n",
    "        les_scores = []\n",
    "        image_array = cv2.imread(image_path)  \n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "        image_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "        results = face_det.process(image_rgb)\n",
    "        if results.detections: \n",
    "            for i, detection in enumerate(results.detections): \n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                h, w, _ = image_rgb.shape\n",
    "                x1 = int(bbox.xmin * w) - int(0.05 * int(bbox.xmin * w))\n",
    "                y1 = int(bbox.ymin * h) - int(0.05 * int(bbox.ymin * h))\n",
    "                x2 = int((bbox.xmin + bbox.width) * w) + int(0.05 * int(bbox.xmin * w))\n",
    "                y2 = int((bbox.ymin + bbox.height) * h) + int(0.05 * int(bbox.ymin * h))\n",
    "                cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                face = image_rgb[y1:y2, x1:x2]\n",
    "                face = cv2.resize(face, (400, 400))\n",
    "                faces.append(face)\n",
    "                les_scores.append(detection.score)\n",
    "    return faces  #, les_scores                     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meshes detection \n",
    "def mesh_detection(face: np.ndarray) -> mp_landmark.NormalizedLandmarkList:\n",
    "    with face_mesh.FaceMesh(\n",
    "            static_image_mode=True,\n",
    "            max_num_faces=10,\n",
    "            min_detection_confidence=0.5,\n",
    "            refine_landmarks=True,\n",
    "            min_tracking_confidence=0.5) as face_meshe:\n",
    "        results = face_meshe.process(face)\n",
    "        if results.multi_face_landmarks:\n",
    "                face_landmarks = results.multi_face_landmarks[0]\n",
    "                #annotated_image = face.copy()\n",
    "                #drawing_utils.draw_landmarks(annotated_image, face_landmarks)\n",
    "                #plt.imshow(annotated_image)\n",
    "                return face_landmarks\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Everything in a single function \n",
    "def image_process(image: Image) -> list:       #list of NormalizedLandmarkList\n",
    "    \n",
    "    #Taking the output list of face_detector \n",
    "    faces = face_detector(image)\n",
    "    \n",
    "    #Loop trough the list to take one face by one face and add it into a list \n",
    "    meshed_coord_faceslist = []\n",
    "    for face in faces:\n",
    "        mesh_coordinates = mesh_detection(face)\n",
    "        if mesh_coordinates:\n",
    "            meshed_coord_faceslist.append(mesh_coordinates)\n",
    "    \n",
    "    # If no face detected return None\n",
    "    if not meshed_coord_faceslist:\n",
    "        return None\n",
    "    \n",
    "    return meshed_coord_faceslist\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_faces = image_process(image_path)\n",
    "# Now you can do a loop on landmarks to apply iris function on one face a the time\n",
    "# for face in landmarks_faces:\n",
    "        # your function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d5199d47e09c264d56960d495f87fb2e9db5e02fdeb85c0cdb762db9136ad67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
